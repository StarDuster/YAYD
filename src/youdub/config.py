from __future__ import annotations

from pathlib import Path
from typing import Optional

from pydantic import Field
from pydantic_settings import BaseSettings, SettingsConfigDict


class Settings(BaseSettings):
    """Centralized configuration loaded from environment variables and .env."""

    # General paths
    root_folder: Path = Field(default=Path("videos"), description="Base folder for downloads and outputs")

    # Demucs
    demucs_model_name: str = Field(
        default="htdemucs_ft",
        description="Demucs model identifier",
        alias="DEMUCS_MODEL_NAME",
    )
    demucs_model_dir: Path = Field(
        default=Path("models/demucs"),
        description="Folder containing Demucs weights (no auto-download)",
        alias="DEMUCS_MODEL_DIR",
    )
    demucs_device: str = Field(default="auto", description="cuda/cpu/auto for Demucs")
    demucs_shifts: int = Field(default=5, description="Number of shifts for Demucs separator")

    # ASR (Whisper via faster-whisper / CTranslate2)
    whisper_model_path: Path = Field(
        default=Path("models/ASR/whisper"),
        description="Path to the locally downloaded faster-whisper CTranslate2 model directory (expects model.bin)",
        alias="WHISPER_MODEL_PATH",
    )
    whisper_cpu_model_path: Optional[Path] = Field(
        default=None,
        description=(
            "Optional path to a CPU-optimized faster-whisper CTranslate2 model directory (e.g., int8). "
            "Used when Whisper device resolves to CPU. If unset, WHISPER_MODEL_PATH will be used."
        ),
        alias="WHISPER_CPU_MODEL_PATH",
    )
    whisper_device: str = Field(
        default="auto",
        description="cuda/cpu/auto for Whisper ASR",
        alias="WHISPER_DEVICE",
    )
    whisper_diarization_model_dir: Optional[Path] = Field(
        default=Path("models/ASR/whisper/diarization"),
        description="Path to diarization model cache (offline, no auto-download)",
        alias="WHISPER_DIARIZATION_MODEL_DIR",
    )
    whisper_model_name: str = Field(
        default="large-v3",
        description="Whisper model name (informational; the actual ASR model is loaded from WHISPER_MODEL_PATH)",
        alias="WHISPER_MODEL_NAME",
    )
    whisper_batch_size: int = Field(default=32, description="Batch size for faster-whisper")

    # Translation
    translation_target_language: str = Field(default="简体中文", description="Default translation target language")

    # TTS
    qwen_tts_model_path: Optional[Path] = Field(
        default=Path("models/TTS/Qwen3-TTS-12Hz-1.7B-Base"),
        description="Local path to Qwen3-TTS Base model directory (no auto-download)",
        alias="QWEN_TTS_MODEL_PATH",
    )
    qwen_tts_python_path: Optional[Path] = Field(
        default=Path(".venv_qwen/bin/python"),
        description="Python executable for Qwen3-TTS runtime (separate venv to avoid dependency conflicts)",
        alias="QWEN_TTS_PYTHON",
    )
    qwen_tts_batch_size: int = Field(
        default=8,
        description="Batch size for Qwen3-TTS (only used when TTS_METHOD=qwen)",
        alias="QWEN_TTS_BATCH_SIZE",
    )
    tts_method: str = Field(
        default="bytedance",
        description="TTS Engine to use (bytedance / gemini / qwen)",
        alias="TTS_METHOD"
    )

    # API tokens / credentials
    hf_token: Optional[str] = Field(default=None, description="HuggingFace token", alias="HF_TOKEN")
    openai_api_key: Optional[str] = Field(default=None, description="OpenAI API key", alias="OPENAI_API_KEY")
    openai_api_base: Optional[str] = Field(default=None, description="OpenAI compatible base URL", alias="OPENAI_API_BASE")
    bytedance_appid: Optional[str] = Field(default=None, description="ByteDance appid", alias="BYTEDANCE_APPID")
    bytedance_access_token: Optional[str] = Field(default=None, description="ByteDance access token", alias="BYTEDANCE_ACCESS_TOKEN")
    model_name: str = Field(default="gpt-3.5-turbo", description="Model name for summary/translation", alias="MODEL_NAME")

    # Bilibili upload
    bili_proxy: Optional[str] = Field(
        default=None,
        description="Bilibili upload proxy (e.g., socks5h://127.0.0.1:1080)",
        alias="BILI_PROXY",
    )
    bili_upload_cdn: Optional[str] = Field(
        default=None,
        description="Preferred upload CDN: bda/bda2/qn/tx/txa/bldsa",
        alias="BILI_UPLOAD_CDN",
    )
    bili_cookie_path: Path = Field(
        default=Path("bili_cookies.json"),
        description="Path to Bilibili cookie file (generated by login)",
        alias="BILI_COOKIE_PATH",
    )
    
    # Gemini TTS
    gemini_api_key: Optional[str] = Field(
        default=None, 
        description="Gemini API key for TTS",
        alias="GEMINI_API_KEY"
    )
    gemini_tts_voice: str = Field(
        default="Kore",
        description="Gemini TTS voice name (30 options)",
        alias="GEMINI_TTS_VOICE"
    )
    gemini_tts_model: str = Field(
        default="gemini-2.5-flash-preview-tts",
        description="Gemini TTS model identifier",
        alias="GEMINI_TTS_MODEL"
    )


    model_config = SettingsConfigDict(
        env_file=".env",
        extra="ignore",
        env_prefix="",
        case_sensitive=False,
        populate_by_name=True,
    )

    def resolve_path(self, path: Optional[Path]) -> Optional[Path]:
        if path is None:
            return None
        # NOTE: Do NOT call `.resolve()` here.
        # Virtualenv python executables are often symlinks to the system interpreter;
        # resolving them would lose the venv context (and break subprocess calls).
        return Path(path).expanduser().absolute()
