# YouTube SRT å¯¹é½è¯´è¯äººåˆ†ç¦»ï¼ˆå‡è®¾ 1 cue = 1 äººï¼‰

ä½ å·²æœ‰ YouTube æä¾›çš„å­—å¹•ï¼ˆä¾‹å¦‚ `ground_truth.en.srt`ï¼‰ã€‚ç›®æ ‡æ˜¯ç”Ÿæˆä¸€ä¸ª**å¸¦è¯´è¯äººæ ‡è®°**çš„æ–°å­—å¹•ï¼ˆä¾‹å¦‚ `ground_truth.en.speaker.srt`ï¼‰ã€‚

è¿™é‡Œçš„â€œå¯¹é½â€æŒ‡ï¼šç”¨è¯´è¯äººåˆ†ç¦»ï¼ˆdiarizationï¼‰çš„ **turnsï¼ˆè°åœ¨ä»€ä¹ˆæ—¶å€™è¯´è¯ï¼‰**ï¼ŒæŒ‰æ—¶é—´é‡å æŠŠæ¯æ¡ YouTube cue è´´ä¸Š speaker æ ‡ç­¾ã€‚

> ä½ å‡è®¾â€œ1 æ¡ cue åªå¯¹åº” 1 ä¸ªè¯´è¯äººâ€ã€‚æˆ‘æŒ‰è¿™ä¸ªå‡è®¾å†™æµç¨‹ã€‚ç°å®é‡Œè¿™ä¸æ€»æˆç«‹ï¼šå¦‚æœä¸€æ¡ cue å†…å‘ç”Ÿæ¢äººï¼Œä½ åªèƒ½å¾—åˆ°â€œä¸»è¯´è¯äººâ€ï¼Œä¼šé”™æ˜¯æ­£å¸¸çš„ã€‚

---

## å‰ç½®æ¡ä»¶

- éœ€è¦ä¸å­—å¹•æ—¶é—´è½´ä¸€è‡´çš„éŸ³é¢‘æ–‡ä»¶ï¼š
  - æ¨èï¼š`audio_vocals.wav`ï¼ˆäººå£°åˆ†ç¦»åçš„è½¨é“ï¼Œä»“åº“æµç¨‹é€šå¸¸ä¼šäº§å‡ºï¼‰
  - å…œåº•ï¼š`audio.wav`ï¼ˆåŸå§‹éŸ³é¢‘ï¼‰
- è¯´è¯äººåˆ†ç¦»ä¾èµ– `pyannote.audio`ï¼Œå¹¶ä¸”éœ€è¦æ¨¡å‹ç¼“å­˜ï¼š
  - ç¯å¢ƒå˜é‡ `WHISPER_DIARIZATION_MODEL_DIR` æŒ‡å‘ç¼“å­˜ç›®å½•ï¼ˆä»“åº“é»˜è®¤ï¼š`models/ASR/whisper/diarization`ï¼‰
  - è‹¥æ²¡æœ‰ç¦»çº¿ç¼“å­˜ï¼Œéœ€è¦è®¾ç½® `HF_TOKEN`ï¼ˆå¹¶åœ¨ HuggingFace åŒæ„ gated æ¨¡å‹åè®®ï¼‰
- **ç”¨ uv ç¯å¢ƒè¿è¡Œ**ï¼ˆæœ¬ä»“åº“çº¦å®šï¼‰ã€‚

---

## è„šæœ¬è¿è¡Œè¯´æ˜ï¼ˆäººè¯ç‰ˆï¼‰

è¿™ä¸ªè„šæœ¬è™½ç„¶çœ‹èµ·æ¥é•¿ï¼Œä½†æ ¸å¿ƒé€»è¾‘å…¶å®éå¸¸ç®€å•ï¼Œä¸»è¦å°±å¹²äº†ä¸‰ä»¶äº‹ï¼š

1.  **å¬å£°éŸ³**ï¼šåˆ©ç”¨ `pyannote` æ¨¡å‹æŠŠéŸ³é¢‘æ–‡ä»¶ä»å¤´åˆ°å°¾å¬ä¸€éï¼Œè®°ä¸‹â€œç¬¬å‡ ç§’åˆ°ç¬¬å‡ ç§’æ˜¯è°åœ¨è¯´è¯â€ï¼ˆè¿™å« Diarizationï¼‰ã€‚
2.  **è¯»å­—å¹•**ï¼šæŠŠä½ çš„ SRT å­—å¹•æ–‡ä»¶è¯»è¿›æ¥ï¼Œè§£æå‡ºæ¯ä¸€å¥è¯çš„å¼€å§‹æ—¶é—´å’Œç»“æŸæ—¶é—´ã€‚
3.  **è¿è¿çœ‹ï¼ˆå¯¹é½ï¼‰**ï¼š
    *   æ‹¿ç€æ¯ä¸€å¥å­—å¹•çš„æ—¶é—´æ®µï¼Œå»å’Œç¬¬ 1 æ­¥é‡Œçš„â€œè¯´è¯äººæ—¶é—´è¡¨â€åšå¯¹æ¯”ã€‚
    *   çœ‹çœ‹è¿™æ®µæ—¶é—´é‡Œï¼Œå“ªä¸ªè¯´è¯äººå‡ºç°çš„æ—¶é•¿æœ€é•¿ï¼ˆé‡å æœ€å¤šï¼‰ã€‚
    *   é‚£å°±è®¤å®šè¿™å¥è¯æ˜¯è¿™ä¸ªäººè¯´çš„ã€‚

æœ€åï¼Œè„šæœ¬ä¼šç”Ÿæˆä¸€ä¸ªæ–°çš„ SRT æ–‡ä»¶ï¼Œå†…å®¹å’ŒåŸæ¥ä¸€æ¨¡ä¸€æ ·ï¼Œåªæ˜¯åœ¨æ¯ä¸€å¥çš„æœ€å‰é¢åŠ ä¸Šäº† `SPEAKER_01: ` è¿™æ ·çš„æ ‡è®°ã€‚

---

## æœ€å°å¯ç”¨è„šæœ¬

ä½ å¯ä»¥ç›´æ¥å¤åˆ¶ä¸‹é¢çš„ä»£ç å—ï¼Œä¿å­˜ä¸º `align_speaker.py` ç„¶åè¿è¡Œï¼Œæˆ–è€…ç›´æ¥åœ¨ç»ˆç«¯é‡Œç²˜è´´è¿è¡Œã€‚

è¯·æ³¨æ„ä¿®æ”¹ `main()` å‡½æ•°é‡Œçš„ `video_dir` è·¯å¾„ä¸ºä½ å®é™…çš„è§†é¢‘æ–‡ä»¶å¤¹ã€‚

```python
cd /home/stardust/source/YouDub-webui

uv run python - <<'PY'
import re
import sys
from pathlib import Path

# === 0. å‡†å¤‡å·¥ä½œï¼šå¤ç”¨ä»“åº“é‡Œç°æˆçš„è½®å­ ===
# æˆ‘ä»¬ç›´æ¥å€Ÿç”¨ YouDub ä»“åº“é‡Œå·²ç»å†™å¥½çš„ä¸¤ä¸ªåŠŸèƒ½ï¼š
# 1. load_diarize_model: è´Ÿè´£åŠ è½½é‚£ä¸ªæ­»æ²‰æ­»æ²‰çš„ pyannote æ¨¡å‹
# 2. _assign_speakers_by_overlap: è´Ÿè´£ç®—â€œè°è¯´è¯æ—¶é—´æœ€é•¿â€è¿™ä¸ªæ•°å­¦é¢˜
sys.path.insert(0, str(Path.cwd() / "src"))
from youdub.steps.transcribe import load_diarize_model, _assign_speakers_by_overlap, _DIARIZATION_PIPELINE

# SRT æ—¶é—´æˆ³çš„æ­£åˆ™æ ¼å¼ (00:00:00,000 --> 00:00:00,000)
TIME = re.compile(
    r"(\d\d):(\d\d):(\d\d),(\d\d\d)\s*-->\s*(\d\d):(\d\d):(\d\d),(\d\d\d)"
)

def to_seconds(h: str, m: str, s: str, ms: str) -> float:
    """æŠŠæ—¶åˆ†ç§’æ¯«ç§’è½¬æˆæ€»ç§’æ•°"""
    return int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000.0

def fmt_srt_time(t: float) -> str:
    """æŠŠç§’æ•°è½¬å› SRT çš„æ—¶é—´æ ¼å¼"""
    ms = int(round(max(0.0, t) * 1000.0))
    h, rem = divmod(ms, 3600_000)
    m, rem = divmod(rem, 60_000)
    s, ms = divmod(rem, 1000)
    return f"{h:02}:{m:02}:{s:02},{ms:03}"

def parse_srt(path: Path) -> list[dict]:
    """
    è¯»å– SRT æ–‡ä»¶ï¼ŒæŠŠå®ƒå˜æˆä¸€ä¸ª Python åˆ—è¡¨ã€‚
    æ¯ä¸€é¡¹é•¿è¿™æ ·ï¼š{'start': 1.5, 'end': 4.2, 'text_lines': ['Hello world'], 'speaker': 'SPEAKER_00'}
    """
    print(f"ğŸ“– æ­£åœ¨è§£æå­—å¹•æ–‡ä»¶: {path.name} ...")
    # utf-8-sig æ˜¯ä¸ºäº†å¤„ç†å¯èƒ½å­˜åœ¨çš„ BOM å¤´
    lines = path.read_text(encoding="utf-8-sig").splitlines()
    cues: list[dict] = []
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        if not line:
            i += 1
            continue
        # è·³è¿‡çº¯æ•°å­—çš„åºå·è¡Œ
        if line.isdigit():
            i += 1
            if i >= len(lines):
                break
            line = lines[i].strip()

        # åŒ¹é…æ—¶é—´è½´è¡Œ
        m = TIME.match(line)
        if not m:
            i += 1
            continue

        start = to_seconds(*m.group(1, 2, 3, 4))
        end = to_seconds(*m.group(5, 6, 7, 8))

        i += 1
        text_lines: list[str] = []
        # è¯»å–æ¥ä¸‹æ¥çš„æ–‡æœ¬è¡Œï¼Œç›´åˆ°é‡åˆ°ç©ºè¡Œ
        while i < len(lines) and lines[i].strip() != "":
            text_lines.append(lines[i])
            i += 1

        cues.append(
            {
                "start": float(start),
                "end": float(end),
                "text_lines": text_lines,
                "speaker": "SPEAKER_00",  # æš‚æ—¶å…ˆå¡«ä¸ªé»˜è®¤çš„ï¼Œä¸€ä¼šå„¿æ”¹
            }
        )
        i += 1
    print(f"âœ… è§£æå®Œæˆï¼Œå…±æ‰¾åˆ° {len(cues)} æ¡å­—å¹•ã€‚")
    return cues

def write_srt(cues: list[dict], out_path: Path) -> None:
    """æŠŠå¤„ç†å¥½çš„åˆ—è¡¨å†™å›æˆ SRT æ–‡ä»¶"""
    out_lines: list[str] = []
    seq = 0
    for cue in cues:
        seq += 1
        out_lines.append(str(seq))
        out_lines.append(f"{fmt_srt_time(cue['start'])} --> {fmt_srt_time(cue['end'])}")

        lines = list(cue.get("text_lines") or [""])
        if not lines:
            lines = [""]

        # åªåœ¨ç¬¬ä¸€è¡ŒåŠ è¯´è¯äººå‰ç¼€ï¼Œè¿™æ ·æ—¢èƒ½çœ‹æ¸…æ˜¯è°è¯´çš„ï¼Œåˆä¸ç ´åå¤šè¡Œæ’ç‰ˆ
        spk = str(cue.get("speaker") or "SPEAKER_00")
        lines[0] = f"{spk}: {lines[0]}".rstrip()

        out_lines.extend(lines)
        out_lines.append("")

    out_path.write_text("\n".join(out_lines), encoding="utf-8")
    print(f"ğŸ’¾ å·²ä¿å­˜å¸¦è¯´è¯äººæ ‡è®°çš„å­—å¹•: {out_path}")

def main() -> None:
    # ---------------------------------------------------------
    # ğŸ‘‡ğŸ‘‡ğŸ‘‡ åªéœ€è¦æ”¹è¿™ä¸€è¡Œè·¯å¾„ ğŸ‘‡ğŸ‘‡ğŸ‘‡
    video_dir = Path(
        "/home/stardust/source/YouDub-webui/videos/More Perfect Union/20250327 I Live 400 Yards From Mark Zuckerbergs Massive Data Center"
    )
    # ---------------------------------------------------------
    
    srt_in = video_dir / "ground_truth.en.srt"
    
    # ä¼˜å…ˆæ‰¾äººå£°åˆ†ç¦»åçš„ wavï¼Œå¦‚æœæ²¡æœ‰å°±æ‰¾åŸå§‹éŸ³é¢‘
    wav = video_dir / "audio_vocals.wav"
    if not wav.exists():
        wav = video_dir / "audio.wav"

    srt_out = video_dir / "ground_truth.en.speaker.srt"

    if not srt_in.exists():
        print(f"âŒ æ‰¾ä¸åˆ°å­—å¹•æ–‡ä»¶: {srt_in}")
        return
    if not wav.exists():
        print(f"âŒ æ‰¾ä¸åˆ°éŸ³é¢‘æ–‡ä»¶: {wav}")
        return

    # 1. è§£æç°æœ‰çš„ SRT
    cues = parse_srt(srt_in)
    if not cues:
        print("âŒ å­—å¹•æ–‡ä»¶æ˜¯ç©ºçš„æˆ–è€…è§£æå¤±è´¥äº†ã€‚")
        return

    # 2. è·‘ Pyannote è¯´è¯äººåˆ†ç¦» (Diarization)
    print("ğŸ¤– æ­£åœ¨åŠ è½½è¯´è¯äººåˆ†ç¦»æ¨¡å‹ (å¯èƒ½éœ€è¦ä¸€ç‚¹æ—¶é—´)...")
    load_diarize_model(device="auto")
    
    print(f"ğŸ§ æ­£åœ¨åˆ†æéŸ³é¢‘ä¸­çš„è¯´è¯äºº: {wav.name} ...")
    # è°ƒç”¨æ¨¡å‹å¤„ç†éŸ³é¢‘
    ann = _DIARIZATION_PIPELINE(str(wav))
    # è·å–ä¸é‡å çš„è¯´è¯äººè½¨é“ (Timeline)
    ann_view = getattr(ann, "exclusive_speaker_diarization", None) or ann
    
    # æŠŠæ¨¡å‹ç»“æœè½¬æ¢æˆç®€å•çš„åˆ—è¡¨
    turns = [
        {"start": float(seg.start), "end": float(seg.end), "speaker": str(spk)}
        for seg, _, spk in ann_view.itertracks(yield_label=True)
    ]
    print(f"âœ… éŸ³é¢‘åˆ†æå®Œæˆï¼Œè¯†åˆ«åˆ° {len(turns)} ä¸ªè¯´è¯ç‰‡æ®µã€‚")

    # 3. æ ¸å¿ƒæ­¥éª¤ï¼šå¯¹é½ (Mapping)
    # ç”¨â€œæ—¶é—´é‡å æœ€å¤§â€åŸåˆ™ï¼ŒæŠŠæ¯æ¡å­—å¹•åˆ†é…ç»™ä¸€ä¸ªè¯´è¯äºº
    print("ğŸ”„ æ­£åœ¨è¿›è¡Œå­—å¹•ä¸è¯´è¯äººçš„å¯¹é½...")
    _assign_speakers_by_overlap(cues, turns, default_speaker="SPEAKER_00")

    # 4. ä¿å­˜ç»“æœ
    write_srt(cues, srt_out)
    print("\nâœ¨ å…¨éƒ¨æå®šï¼å¿«å»çœ‹çœ‹ç”Ÿæˆçš„æ–‡ä»¶å§ã€‚")

if __name__ == "__main__":
    main()
PY
```

---

## è¿™å¥—å¯¹é½åœ¨ä»€ä¹ˆæƒ…å†µä¸‹ä¼šæ˜æ˜¾ä¸å‡†

- ä½ çš„ YouTube `ground_truth.en.srt` çš„æ—¶é—´è½´ä¸æœ¬åœ° `audio_vocals.wav` / `audio.wav` **ä¸æ˜¯åŒä¸€ä¸ªç‰ˆæœ¬**ï¼ˆä¾‹å¦‚è¢«åŠ é€Ÿã€å‰ªè¾‘ã€é‡ç¼–ç åç§»ï¼‰ã€‚
- ä¸€æ¡ cue å†…ç¡®å®åŒ…å«å¤šä¸ªäººè¯´è¯ï¼ˆä½ å½“å‰å‡è®¾ä¸æˆç«‹ï¼‰ã€‚
- diarization æœ¬èº«åˆ†é”™äººï¼ˆå°¤å…¶æ˜¯èƒŒæ™¯å™ªå£°å¤§ã€å¤šäººé‡å è®²è¯ã€å¼ºæ··å“çš„ç‰‡æ®µï¼‰ã€‚

